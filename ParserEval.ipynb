{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_text_file(filename, outfile, limit=1000):\n",
    "    with open(filename, \"r\", encoding='utf8') as f, open(outfile, 'w', encoding='utf8') as o:\n",
    "        i=0\n",
    "        for line in f:\n",
    "            if line[:9] == '# text = ': \n",
    "                text = line[9:]\n",
    "                i+=1\n",
    "                o.write(text)\n",
    "                \n",
    "                if i==limit:\n",
    "                    break\n",
    "    print(f'Wrote {i} sentences to file.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 1000 sentences to file.\n",
      "Wrote 1000 sentences to file.\n",
      "Wrote 1000 sentences to file.\n"
     ]
    }
   ],
   "source": [
    "make_text_file('conllu-files/en_formal.conllu', 'en_formal.txt')\n",
    "make_text_file('conllu-files/en_literature.conllu', 'en_literature.txt')\n",
    "make_text_file('conllu-files/en_news.conllu', 'en_news.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 1000 sentences to file.\n",
      "Wrote 1000 sentences to file.\n",
      "Wrote 1000 sentences to file.\n"
     ]
    }
   ],
   "source": [
    "make_text_file('conllu-files/sv_formal.conllu', 'sv_formal.txt')\n",
    "make_text_file('conllu-files/sv_literature.conllu', 'sv_literature.txt')\n",
    "make_text_file('conllu-files/sv_news.conllu', 'sv_news.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_conllu(filename, limit=1000):\n",
    "    '''Returns a dict of (sent_tokens...):{'upos':[upos_tags...], 'xpos':[xpos_tags}'''\n",
    "    \n",
    "    with open(filename, \"r\", encoding='utf8') as f:\n",
    "        \n",
    "        sentences = {}\n",
    "        tokens = []\n",
    "        upos_tags = []\n",
    "        xpos_tags = []\n",
    "        deprels = []\n",
    "        \n",
    "        \n",
    "        for line in f:\n",
    "            if line[0] == '#': #skip '# newdoc id = n01001', '# sent_id = n01001011'\n",
    "                continue\n",
    "            columns = line.split() # 10 cols\n",
    "            if columns == []: # When reading a blank line => finish reading one sentence\n",
    "                sentence_text = tuple(tokens)\n",
    "                sentences[sentence_text] = {}\n",
    "                sentences[sentence_text]['upos'] = upos_tags\n",
    "                sentences[sentence_text]['xpos'] = xpos_tags\n",
    "                sentences[sentence_text]['deprel'] = deprels\n",
    "                tokens, upos_tags, xpos_tags, deprels = [], [], [], [] # Reset the pos lists\n",
    "                \n",
    "                \n",
    "                if len(sentences)>=limit:\n",
    "                    break\n",
    "                continue\n",
    "                \n",
    "            tokens.append(columns[1])\n",
    "            upos_tags.append(columns[3])\n",
    "            xpos_tags.append(columns[4].split('|')[0]) # if XX|YY|ZZ => only keep XX\n",
    "            deprels.append(columns[6]+'_'+columns[7]) # head id, deprel tag\n",
    "            \n",
    "\n",
    "            \n",
    "    print(f'Corpus contains {len(sentences)} sentences.')\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus contains 1000 sentences.\n",
      "Corpus contains 1000 sentences.\n",
      "Corpus contains 1000 sentences.\n",
      "Corpus contains 1000 sentences.\n",
      "Corpus contains 1000 sentences.\n",
      "Corpus contains 1000 sentences.\n"
     ]
    }
   ],
   "source": [
    "# key = tuple of tokens of a sentence\n",
    "# dict[key]['upos'] = true POS labels\n",
    "eng_formal = read_conllu('conllu-files/en_formal.conllu')\n",
    "eng_literature = read_conllu('conllu-files/en_literature.conllu')\n",
    "eng_news = read_conllu('conllu-files/en_news.conllu')\n",
    "\n",
    "swe_formal = read_conllu('conllu-files/sv_formal.conllu')\n",
    "swe_literature = read_conllu('conllu-files/sv_literature.conllu')\n",
    "swe_news = read_conllu('conllu-files/sv_news.conllu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def read_sparv_xml(filename):\n",
    "    '''Reads the XML file from Sparv annotation and return the texts and \n",
    "    the POS and MSD tags'''\n",
    "    with open(filename, \"r\", encoding='utf8') as f:\n",
    "        \n",
    "        sentences = {}\n",
    "        \n",
    "        for line in f:\n",
    "            if line[:3]=='<se':\n",
    "                tokens = []\n",
    "                pos_tags = []\n",
    "                msd_tags = []\n",
    "                deprels = [] \n",
    "                \n",
    "            if line[:3]=='<w ':\n",
    "                token = re.findall('(?<=>)[^\\s]+(?=</w>)', line)[0]\n",
    "                pos = re.findall('(?<=pos=\")[^\\s]+(?=\"\\sm)', line)[0]\n",
    "                msd = re.findall('(?<=msd=\")[^\\s]+(?=\"\\s)', line)[0]\n",
    "                try:\n",
    "                    head_id = re.findall('(?<=dephead=\")[^\\s]*(?=\"\\s)', line)[0]\n",
    "                    deprel_tag = re.findall('(?<=deprel=\")[^\\s]+(?=\">)', line)[0]\n",
    "                    \n",
    "                except IndexError:\n",
    "                    head_id, deprel_tag = '_', '_'\n",
    "                \n",
    "                if msd[0]=='F' and msd[1:].islower():\n",
    "                    msd = token # change tag to the punctuation itself\n",
    "                if pos=='PROPN' and len(token.split('_'))>1: #split multiword PropN \n",
    "                    propn_tokens = token.split('_')\n",
    "                    tokens.extend(propn_tokens)\n",
    "                    pos_tags.extend([pos]*len(propn_tokens))\n",
    "                    msd_tags.extend([msd]*len(propn_tokens))\n",
    "                    deprels.extend([head_id+'_'+deprel_tag]*len(propn_tokens))\n",
    "                    continue\n",
    "                \n",
    "                tokens.append(token)\n",
    "                pos_tags.append(pos)\n",
    "                msd_tags.append(msd)\n",
    "                deprels.append(head_id+'_'+deprel_tag)\n",
    "            \n",
    "            if line[:3]=='</s':\n",
    "                sentence_text = tuple(tokens)\n",
    "                sentences[sentence_text] = {}\n",
    "                sentences[sentence_text]['pos'] = pos_tags\n",
    "                sentences[sentence_text]['msd'] = msd_tags\n",
    "                sentences[sentence_text]['deprel'] = deprels\n",
    "                \n",
    "    print(f'Parser output contains {len(sentences)} sentences.')       \n",
    "    return sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parser output contains 986 sentences.\n",
      "Parser output contains 993 sentences.\n",
      "Parser output contains 948 sentences.\n",
      "Parser output contains 1025 sentences.\n",
      "Parser output contains 866 sentences.\n",
      "Parser output contains 911 sentences.\n"
     ]
    }
   ],
   "source": [
    "# key = tuple of tokenized sentence\n",
    "# dict[key]['pos'] = predicted POS labels\n",
    "sparv_en_news = read_sparv_xml('parsed/en_news_parsed.xml')\n",
    "sparv_sv_news = read_sparv_xml('parsed/sv_news_parsed.xml')\n",
    "\n",
    "sparv_en_lit = read_sparv_xml('parsed/en_lit_parsed.xml')\n",
    "sparv_sv_lit = read_sparv_xml('parsed/sv_lit_parsed.xml')\n",
    "\n",
    "sparv_en_formal = read_sparv_xml('parsed/en_formal_parsed.xml')\n",
    "sparv_sv_formal = read_sparv_xml('parsed/sv_formal_parsed.xml')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shared_keys(dict1, dict2):\n",
    "    d1_set = set(dict1)\n",
    "    d2_set = set(dict2)\n",
    "    return d1_set.intersection(d2_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "def model_performance(y_true: List[List[str]],\n",
    "                      y_pred: List[List[str]]) -> Dict[str, float]:\n",
    "    \"\"\"Accuracy calculation function\n",
    "    \n",
    "    Args:\n",
    "      y_true: List of true labels of the tokenized sentense.\n",
    "      y_pred: List of predicted labels of the tokenized sentense.\n",
    "      \n",
    "    Returns:\n",
    "      Dict of metrics:\n",
    "      \n",
    "        {\n",
    "          \"accuracy\": float,\n",
    "          \"f1_micro\": float,\n",
    "          \"f1_macro\": float,\n",
    "          \"f1_weighted\": float,\n",
    "        }\n",
    "    \n",
    "    Raises:\n",
    "      ValueError: Exception occurred when input lists' length don't match.\n",
    "    \"\"\"\n",
    "    if len(y_true) == 0:\n",
    "        return None\n",
    "    \n",
    "    if len(y_true) != len(y_pred):\n",
    "        raise ValueError(\"Lengths of input lists don't match.\")\n",
    "    \n",
    "    def _list_flattener(inpt: List[List[str]]) -> List[str]:\n",
    "        \"\"\"Flattener for list of lists into a single list.\"\"\"\n",
    "        output = []\n",
    "        for i in inpt:\n",
    "            output.extend(i)\n",
    "        return output\n",
    "\n",
    "    y_true = _list_flattener(y_true)\n",
    "    y_pred = _list_flattener(y_pred)\n",
    "\n",
    "    if len(y_true) != len(y_pred):\n",
    "        raise ValueError(\"Numper of tokens don't match between y_true and y_pred.\")\n",
    "    \n",
    "    try:\n",
    "        metrics = {\n",
    "          \"accuracy\": accuracy_score(y_true, y_pred),\n",
    "          \"f1_micro\": f1_score(y_true, y_pred, average='micro'),\n",
    "          \"f1_macro\": f1_score(y_true, y_pred, average='macro'),\n",
    "          \"f1_weighted\": f1_score(y_true, y_pred, average='weighted'),\n",
    "        }\n",
    "    except Exception as ex:\n",
    "        raise Exception(f\"Metrics calculation error: {ex}\")\n",
    "    return metrics\n",
    "\n",
    "def eval_domain(corpora_dict, sparv_dict, lang='en'):\n",
    "    \n",
    "    common_keys = shared_keys(corpora_dict, sparv_dict)\n",
    "    common_keys = list(common_keys)\n",
    "    print(f'UD corpora has {len(corpora_dict)} sentences.')\n",
    "    print(f'Sparv parsing has {len(sparv_dict)} sentences.')\n",
    "    print(f'{len(common_keys)} sentences in common.')\n",
    "    print(f'Evaluate {len(common_keys)} sentences and their POS tagging prediction.')\n",
    "    print()\n",
    "    \n",
    "    true_pos = [corpora_dict[key]['upos'] for key in common_keys]\n",
    "    if lang=='en':\n",
    "        pred_pos = [sparv_dict[key]['pos'] for key in common_keys]\n",
    "    if lang=='sv':\n",
    "        sv_pos_mapping = {'AB':'ADV', 'DT':'DET','HA':'ADV','HD':'DET','HP':'PRON','HS':'PRON',\n",
    "                     'IE':'PART','IN':'INTJ','JJ':'ADJ','KN':'CCONJ','MAD':'PUNCT','MID':'PUNCT', \n",
    "                    'NN':'NOUN','PAD':'PUNCT','PC':'ADJ','PL':'ADV','PM':'PROPN','PN':'PRON',\n",
    "                 'PP':'ADP','PS':'PRON','RG':'NUM','RO':'ADJ','SN':'SCONJ','UO':'NOUN','VB':'VERB'}\n",
    "        pred_pos = [ [sv_pos_mapping[p] for p in sparv_dict[key]['pos']]\n",
    "                    for key in common_keys]\n",
    "    results = model_performance(true_pos, pred_pos)\n",
    "    for x in results.items():\n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UD corpora has 1000 sentences.\n",
      "Sparv parsing has 986 sentences.\n",
      "674 sentences in common.\n",
      "Evaluate 674 sentences and their POS tagging prediction.\n",
      "\n",
      "('accuracy', 0.8282548476454293)\n",
      "('f1_micro', 0.8282548476454293)\n",
      "('f1_macro', 0.5532475082428272)\n",
      "('f1_weighted', 0.803869911880206)\n"
     ]
    }
   ],
   "source": [
    "# News - English\n",
    "eval_domain(eng_news, sparv_en_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UD corpora has 1000 sentences.\n",
      "Sparv parsing has 866 sentences.\n",
      "563 sentences in common.\n",
      "Evaluate 563 sentences and their POS tagging prediction.\n",
      "\n",
      "('accuracy', 0.8055015552099534)\n",
      "('f1_micro', 0.8055015552099534)\n",
      "('f1_macro', 0.5339737946716463)\n",
      "('f1_weighted', 0.7783730346142022)\n"
     ]
    }
   ],
   "source": [
    "# Formal - English\n",
    "eval_domain(eng_formal, sparv_en_formal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UD corpora has 1000 sentences.\n",
      "Sparv parsing has 948 sentences.\n",
      "680 sentences in common.\n",
      "Evaluate 680 sentences and their POS tagging prediction.\n",
      "\n",
      "('accuracy', 0.8209931368591038)\n",
      "('f1_micro', 0.8209931368591038)\n",
      "('f1_macro', 0.5411824644851406)\n",
      "('f1_weighted', 0.7964196366156389)\n"
     ]
    }
   ],
   "source": [
    "# Lit - English\n",
    "eval_domain(eng_literature, sparv_en_lit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UD corpora has 1000 sentences.\n",
      "Sparv parsing has 993 sentences.\n",
      "941 sentences in common.\n",
      "Evaluate 941 sentences and their POS tagging prediction.\n",
      "\n",
      "('accuracy', 0.9141556105239488)\n",
      "('f1_micro', 0.9141556105239487)\n",
      "('f1_macro', 0.7800863457485648)\n",
      "('f1_weighted', 0.8975377625157782)\n"
     ]
    }
   ],
   "source": [
    "# News - Swedish\n",
    "eval_domain(swe_news, sparv_sv_news, lang='sv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UD corpora has 1000 sentences.\n",
      "Sparv parsing has 911 sentences.\n",
      "763 sentences in common.\n",
      "Evaluate 763 sentences and their POS tagging prediction.\n",
      "\n",
      "('accuracy', 0.8990748528174937)\n",
      "('f1_micro', 0.8990748528174937)\n",
      "('f1_macro', 0.7858239841217034)\n",
      "('f1_weighted', 0.8797052761356009)\n"
     ]
    }
   ],
   "source": [
    "# Formal - Swedish\n",
    "eval_domain(swe_formal, sparv_sv_formal, lang='sv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UD corpora has 1000 sentences.\n",
      "Sparv parsing has 1025 sentences.\n",
      "935 sentences in common.\n",
      "Evaluate 935 sentences and their POS tagging prediction.\n",
      "\n",
      "('accuracy', 0.9050810940211862)\n",
      "('f1_micro', 0.9050810940211862)\n",
      "('f1_macro', 0.8426980236395304)\n",
      "('f1_weighted', 0.8867692842459612)\n"
     ]
    }
   ],
   "source": [
    "# Lit - Swedish\n",
    "eval_domain(swe_literature, sparv_sv_lit, lang='sv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eng_to_swe_equivalent(eng_corpus, swe_corpus, out_fn):\n",
    "    \n",
    "    with open(out_fn, \"w\", encoding='utf8') as o:\n",
    "    \n",
    "        for eng_corpora, swe_corpora in list(zip(eng_corpus,swe_corpus)):\n",
    "            with open(eng_corpora, \"r\", encoding='utf8') as en, open(swe_corpora, \"r\", encoding='utf8') as sv:\n",
    "\n",
    "                swe_sent_ids = []\n",
    "                for line in en:\n",
    "                    if line[:14] == '# sent_id = en': # sent_id = en_lines-ud-dev-doc2-3296\n",
    "                        swe_sent_id = 'sv' + line[14:].rstrip('\\n')\n",
    "                        swe_sent_ids.append(swe_sent_id)\n",
    "\n",
    "\n",
    "                sv_lines = [l.rstrip('\\n') for l in sv]\n",
    "                for line in sv_lines:\n",
    "                    if line[:12] == '# sent_id = ':\n",
    "                        send_id = line[12:]\n",
    "                        if send_id in swe_sent_ids:\n",
    "                            i = sv_lines.index(line)\n",
    "                            while sv_lines[i]!='':\n",
    "                                o.write(sv_lines[i]+'\\n') # write send_id ~ last token\n",
    "                                i+=1\n",
    "                            o.write('\\n')\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "eng_to_swe_equivalent([f'domains/literature/en_lines-ud-{x}.conllu' for x in ['train', 'dev', 'test']], \n",
    "                     [f'UD/UD_Swedish-LinES/sv_lines-ud-{x}.conllu' for x in ['train', 'dev', 'test']],\n",
    "                     'sv_literature.conllu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_corpus(corpus, out_fn):\n",
    "    with open(out_fn, \"w\", encoding='utf8') as o:\n",
    "        for corpora in corpus:\n",
    "            with open(corpora, \"r\", encoding='utf8') as f:\n",
    "                for line in f:\n",
    "                    o.write(line)\n",
    "merge_corpus([f'domains/literature/en_lines-ud-{x}.conllu' for x in ['train', 'dev', 'test']],\n",
    "            'en_literature.conllu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formal_corpus(lines_fn, lit_fn, out_fn):\n",
    "    # LinEs - Literature = formal\n",
    "    with open(out_fn, \"w\", encoding='utf8') as o:\n",
    "\n",
    "        with open(lines_fn, \"r\", encoding='utf8') as lines, open(lit_fn, \"r\", encoding='utf8') as lit:\n",
    "            \n",
    "            lit_ids = []\n",
    "            for line in lit:\n",
    "                if line[:14] == '# sent_id = en': # sent_id = en_lines-ud-dev-doc2-3296\n",
    "                    lit_id = 'sv' + line[12:].rstrip('\\n')\n",
    "                    lit_ids.append(lit_id)\n",
    "                    \n",
    "            lines_l = [l.rstrip('\\n') for l in lines]\n",
    "            for line in lines_l:\n",
    "                if line[:12] == '# sent_id = ':\n",
    "                    send_id = line[12:]\n",
    "                    if send_id not in lit_ids:\n",
    "                        i = lines_l.index(line)\n",
    "                        while lines_l[i]!='':\n",
    "                            o.write(lines_l[i]+'\\n') # write send_id ~ last token\n",
    "                            i+=1\n",
    "                        o.write('\\n')\n",
    "                            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AB',\n",
       " 'DT',\n",
       " 'HA',\n",
       " 'HD',\n",
       " 'HP',\n",
       " 'HS',\n",
       " 'IE',\n",
       " 'IN',\n",
       " 'JJ',\n",
       " 'KN',\n",
       " 'MAD',\n",
       " 'MID',\n",
       " 'NN',\n",
       " 'PAD',\n",
       " 'PC',\n",
       " 'PL',\n",
       " 'PM',\n",
       " 'PN',\n",
       " 'PP',\n",
       " 'PS',\n",
       " 'RG',\n",
       " 'RO',\n",
       " 'SN',\n",
       " 'UO',\n",
       " 'VB'}"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sv_pos = set()\n",
    "for c in (sparv_sv_formal, sparv_sv_lit, sparv_sv_news):\n",
    "    \n",
    "    for v in c.values():\n",
    "        some_pos = v['pos']\n",
    "        sv_pos.update(some_pos)\n",
    "    \n",
    "len(sv_pos)\n",
    "sv_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'000',\n",
       " '15',\n",
       " '3',\n",
       " 'AB',\n",
       " 'AD-DEF',\n",
       " 'AD-DEF-GEN',\n",
       " 'AD-PL-DEF',\n",
       " 'AD-PL-IND',\n",
       " 'AD-SG-IND',\n",
       " 'ADJ-PL',\n",
       " 'ADJ-PL-GEN',\n",
       " 'ADJ-PL-NOM',\n",
       " 'ADJ-SG',\n",
       " 'ADJ-SG-IND',\n",
       " 'AUX',\n",
       " 'CARD',\n",
       " 'CARD-PL',\n",
       " 'CARD-SG',\n",
       " 'CMP',\n",
       " 'CMP-DEF',\n",
       " 'CMP-IND',\n",
       " 'CMP-PL-IND',\n",
       " 'CNJ',\n",
       " 'Colon',\n",
       " 'Comma',\n",
       " 'DEF-FGN',\n",
       " 'DEF-NOM',\n",
       " 'DEM-PL',\n",
       " 'DEM-SG',\n",
       " 'DEM-SG-IND',\n",
       " 'DT',\n",
       " 'Dash',\n",
       " 'Dots',\n",
       " 'EX-P3SG',\n",
       " 'ExclMark',\n",
       " 'FGN',\n",
       " 'FGN-NOM',\n",
       " 'HA',\n",
       " 'HD',\n",
       " 'HP',\n",
       " 'HS',\n",
       " 'ID',\n",
       " 'IE',\n",
       " 'IM',\n",
       " 'IMP-ACT',\n",
       " 'IN',\n",
       " 'IND',\n",
       " 'IND-GEN',\n",
       " 'IND-NOM',\n",
       " 'IND-PFX',\n",
       " 'IND-PL',\n",
       " 'IND-SG',\n",
       " 'IND-SG-NOM',\n",
       " 'INF-ACT',\n",
       " 'INF-AUX',\n",
       " 'INF-DPO',\n",
       " 'INF-PASS',\n",
       " 'JJ',\n",
       " 'KN',\n",
       " 'LeftParenthesis',\n",
       " 'MAD',\n",
       " 'MID',\n",
       " 'NDE',\n",
       " 'NDE-NOM',\n",
       " 'NEG',\n",
       " 'NEG-PL-IND',\n",
       " 'NEG-SG',\n",
       " 'NEG-SG-IND',\n",
       " 'NN',\n",
       " 'NOM',\n",
       " 'NOM-FGN',\n",
       " 'NOUN',\n",
       " 'ORD',\n",
       " 'P1PL-GEN-PL',\n",
       " 'P1PL-GEN-SG',\n",
       " 'P1SG-GEN-PL',\n",
       " 'P1SG-GEN-SG',\n",
       " 'P2PL-GEN-PL',\n",
       " 'P2PL-GEN-SG',\n",
       " 'P2SG-GEN-PL',\n",
       " 'P2SG-GEN-SG',\n",
       " 'P3PL-GEN',\n",
       " 'P3SG-GEN',\n",
       " 'PAD',\n",
       " 'PAST',\n",
       " 'PAST-ACT',\n",
       " 'PAST-AUX',\n",
       " 'PAST-DPO',\n",
       " 'PAST-PASS',\n",
       " 'PC',\n",
       " 'PERS-P1PL-ACC',\n",
       " 'PERS-P1PL-NOM',\n",
       " 'PERS-P1SG-ACC',\n",
       " 'PERS-P1SG-NOM',\n",
       " 'PERS-P2PL-ACC',\n",
       " 'PERS-P2PL-NOM',\n",
       " 'PERS-P2SG-ACC',\n",
       " 'PERS-P2SG-NOM',\n",
       " 'PERS-P3-NOM',\n",
       " 'PERS-P3PL-ACC',\n",
       " 'PERS-P3PL-NOM',\n",
       " 'PERS-P3SG',\n",
       " 'PERS-P3SG-ACC',\n",
       " 'PERS-P3SG-NOM',\n",
       " 'PERS-SG-NOM',\n",
       " 'PL',\n",
       " 'PL-DEF',\n",
       " 'PL-DEF-GEN',\n",
       " 'PL-DEF-NOM',\n",
       " 'PL-FGN',\n",
       " 'PL-GEN',\n",
       " 'PL-IND',\n",
       " 'PL-IND-FGN',\n",
       " 'PL-IND-GEN',\n",
       " 'PL-IND-NOM',\n",
       " 'PL-NOM',\n",
       " 'PL-NOM-FGN',\n",
       " 'PM',\n",
       " 'PN',\n",
       " 'POS',\n",
       " 'POS-DEF',\n",
       " 'POS-DEF-GEN',\n",
       " 'POS-FGN',\n",
       " 'POS-IND',\n",
       " 'POS-PFX',\n",
       " 'POS-PL-DEF',\n",
       " 'POS-PL-IND',\n",
       " 'POS-SG-DEF',\n",
       " 'POS-SG-DEF-GEN',\n",
       " 'POS-SG-IND',\n",
       " 'PP',\n",
       " 'PRES',\n",
       " 'PRES-ACT',\n",
       " 'PRES-AUX',\n",
       " 'PRES-DPO',\n",
       " 'PRES-PASS',\n",
       " 'PS',\n",
       " 'Period',\n",
       " 'QuestionMark',\n",
       " 'Quote',\n",
       " 'RCP-PL-ACC',\n",
       " 'REL',\n",
       " 'RFL-ACC',\n",
       " 'RFL-PL-GEN',\n",
       " 'RFL-SG-GEN',\n",
       " 'RG',\n",
       " 'RO',\n",
       " 'RightParenthesis',\n",
       " 'SBJ-AUX',\n",
       " 'SG-DEF',\n",
       " 'SG-DEF-GEN',\n",
       " 'SG-DEF-NOM',\n",
       " 'SG-FGN',\n",
       " 'SG-FGN-NOM',\n",
       " 'SG-GEN',\n",
       " 'SG-GEN-FGN',\n",
       " 'SG-IND',\n",
       " 'SG-IND-DAT',\n",
       " 'SG-IND-FGN',\n",
       " 'SG-IND-GEN',\n",
       " 'SG-IND-NOM',\n",
       " 'SG-IND-PFX',\n",
       " 'SG-NOM',\n",
       " 'SG-NOM-FGN',\n",
       " 'SN',\n",
       " 'SPL',\n",
       " 'SPL-DEF',\n",
       " 'SPL-NOM',\n",
       " 'SPL-PL',\n",
       " 'SPL-PL-IND',\n",
       " 'SPL-SG-DEF',\n",
       " 'SPL-SG-IND',\n",
       " 'SUP-ACT',\n",
       " 'SUP-AUX',\n",
       " 'SUP-DPO',\n",
       " 'SUP-PASS',\n",
       " 'SemiColon',\n",
       " 'TOT',\n",
       " 'TOT-PL',\n",
       " 'TOT-PL-NOM',\n",
       " 'TOT-SG',\n",
       " 'TOT-SG-IND',\n",
       " 'TOT-SG-NOM',\n",
       " 'UO',\n",
       " 'VB',\n",
       " 'WH',\n",
       " 'WH-PL-IND',\n",
       " 'WH-REL',\n",
       " 'WH-REL-GEN',\n",
       " 'WH-REL-PL',\n",
       " 'WH-REL-PL-GEN',\n",
       " 'WH-REL-SG',\n",
       " 'WH-SG',\n",
       " 'WH-SG-IND',\n",
       " 'WH-SG-REL',\n",
       " '_'}"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sv_ud_pos = set()\n",
    "for c in (swe_formal, swe_literature, swe_news):\n",
    "    \n",
    "    for v in c.values():\n",
    "        some_pos = v['xpos']\n",
    "        sv_ud_pos.update(some_pos)\n",
    "    \n",
    "len(sv_ud_pos)\n",
    "sv_ud_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "157"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_pos = set()\n",
    "# for c in (sparv_en_formal, sparv_en_lit, sparv_en_news):\n",
    "for c in (eng_formal, eng_literature, eng_news):\n",
    "    \n",
    "    for v in c.values():\n",
    "        some_pos = v['xpos']\n",
    "        en_pos.update(some_pos)\n",
    "    \n",
    "len(en_pos)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
